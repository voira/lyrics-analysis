{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\packaging\\core.py:99: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.datetime.utcnow()\n",
      "c:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\packaging\\core.py:99: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"fixed.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns= {\"Column1\" : \"Rank\"}, inplace= True)\n",
    "df.rename(columns= {\"Column2\" : \"Title\"}, inplace= True)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"3 There's a summer place_x000D_\\nWhere it may rain or storm_x000D_\\nYet I'm safe and warm_x000D_\\nFor within that summer place_x000D_\\nYour arms reach out to me_x000D_\\nAnd my heart is free from all care_x000D_\\nFor it knows_x000D_\\n_x000D_\\nThere are no gloomy skies_x000D_\\nWhen seen through the eyes_x000D_\\nOf those who are blessed with love_x000D_\\n_x000D_\\nAnd the sweet secret of_x000D_\\nA summer place_x000D_\\nIs that it's anywhere_x000D_\\nWhen two people share_x000D_\\nAll their hopes_x000D_\\nAll their dreams_x000D_\\nAll their love_x000D_\\n_x000D_\\nAnd the sweet secret of a summer place_x000D_\\nIs that it's anywhere_x000D_\\nWhen two people share_x000D_\\nAll their hopes_x000D_\\nAll their dreams, all their love\""
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Lyrics\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings to be replaced\n",
    "old_string = '_x000D_'\n",
    "new_string = ' '\n",
    "\n",
    "# Replace the string in the DataFrame\n",
    "df = df.map(lambda x: x.replace(old_string, new_string) if isinstance(x, str) else x)\n",
    "df['Lyrics'] = df['Lyrics'].astype(str).str.replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"Year\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the corpus\n",
    "corpus = df[\"Lyrics\"].tolist()\n",
    "print(len(corpus))\n",
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "lyric_corpus_tokenized = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for lyric in corpus:\n",
    "    tokenized_lyric = tokenizer.tokenize(lyric.lower())\n",
    "    lyric_corpus_tokenized.append(tokenized_lyric)\n",
    "\n",
    "print(len(lyric_corpus_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter short words\n",
    "for s, song in enumerate(lyric_corpus_tokenized):\n",
    "    filtered_song = []\n",
    "    for token in song:\n",
    "        if len(token) > 2:\n",
    "            filtered_song.append(token)\n",
    "    lyric_corpus_tokenized[s] = filtered_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize the words\n",
    "for s, song in enumerate(lyric_corpus_tokenized):\n",
    "    lemmatized_tokens = []\n",
    "    for token in song:\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "    lyric_corpus_tokenized[s] = lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Filter stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "new_stop_words = [\n",
    "    'ooh', 'yeah', 'hey', 'whoa', 'woah', 'ohh', 'mmm', 'oooh', 'yah', 'yeh', 'hmm',\n",
    "    'deh', 'doh', 'jah', 'let', 'ah', 'uhh', 'ha', 'eh', 'wow', 'yay', 'oops', 'ouch',\n",
    "    'phew', 'ugh', 'yup', 'nope', 'okay', 'ok', 'nah', 'duh', 'aww', 'tsk', 'shh',\n",
    "    'whee', 'yay', 'huh', 'bro', 'dude', 'sis', 'man', 'buddy', 'pal', 'gal', 'like',\n",
    "    'literally', 'basically', 'actually', 'totally', 'seriously', 'just', 'really',\n",
    "    'very', 'so', 'well', 'you know', 'I mean', 'kind of', 'sort of', 'kind', 'sort',\n",
    "    'maybe', 'perhaps', 'aint', 'gonna', 'wanna', 'gotta', 'lemme', 'dunno', 'kinda',\n",
    "    'sorta', 'whatcha', 'uh-huh', 'huh-uh', 'woohoo', 'be', 'have', 'do', 'say', 'get',\n",
    "    'make', 'go', 'know', 'take', 'see', 'come', 'think', 'look', 'want', 'give', 'use',\n",
    "    'find', 'tell', 'ask', 'seem', 'feel', 'try', 'leave', 'call', 'is', 'are',\n",
    "    'was', 'were', 'been', 'am', 'has', 'had', 'does', 'did', 'says', 'gets', 'makes',\n",
    "    'goes', 'knows', 'takes', 'sees', 'comes', 'thinks', 'looks', 'wants', 'gives', 'uses',\n",
    "    'finds', 'tells', 'asks', 'works', 'seems', 'tries', 'leaves', \"said\", \"new\", \"got\", \"ayy\", \"gon\", \"doo\", \n",
    "    \"wa\", \"away\", \"one\", \"two\", \"put\", \"ever\", \"never\", \"cause\", \"time\", \"every\", \"always\"\n",
    "]\n",
    "stop_words.extend(new_stop_words)\n",
    "\n",
    "for s, song in enumerate(lyric_corpus_tokenized):\n",
    "    filtered_text = []\n",
    "    for token in song:\n",
    "        if token not in stop_words:\n",
    "            filtered_text.append(token)\n",
    "    lyric_corpus_tokenized[s] = filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<2609 unique tokens: ['anywhere', 'arm', 'blessed', 'care', 'dream']...>\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Define the dictionary\n",
    "dictionary = Dictionary(lyric_corpus_tokenized)\n",
    "dictionary.filter_extremes(no_below = 20, no_above=0.5, keep_n=50000)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import MmCorpus\n",
    "\n",
    "# Create the dictionary for gensim\n",
    "gensim_corpus = [dictionary.doc2bow(song) for song in lyric_corpus_tokenized]\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "chunksize = 500\n",
    "passes = 20\n",
    "iterations = 50\n",
    "num_topics = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Train the model\n",
    "lda_model = LdaModel(\n",
    "    corpus = gensim_corpus,\n",
    "    id2word = id2word,\n",
    "    chunksize = chunksize,\n",
    "    alpha= \"auto\",\n",
    "    eta = \"auto\", \n",
    "    iterations = iterations,\n",
    "    num_topics = num_topics,\n",
    "    passes = passes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4279299874101532\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "coherencemodel = CoherenceModel(model=lda_model, texts=lyric_corpus_tokenized, dictionary=dictionary, coherence='c_v')\n",
    "print(coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "c:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "c:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n",
      "c:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "c:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "vis_data = gensimvis.prepare(lda_model, gensim_corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)\n",
    "pyLDAvis.save_html(vis_data, './Lyrics_LDA_k_'+ str(num_topics) +'.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
